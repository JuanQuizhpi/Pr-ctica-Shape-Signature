{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Universidad Politécnica Salesiana\n",
        "## Realizado por: Juan Francisco Quizhpi ,Edwin Paul Paute"
      ],
      "metadata": {
        "id": "VkoRGCFK-Ut6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reporte Parte 2\n",
        "\n",
        "### Introducción\n",
        "\n",
        "El objetivo de este proyecto es el diseño de un sistema de clasificación de imágenes. Para esta ocasión se opta por el uso del descriptor \"Shape Signature\". Este nos ayuda a capturar la información de un objeto que nos permitirá realizar una clasificación en función de sus medidas de similitud. En este pequeño reporte daremos a conocer los pasos realizados para obtener los descriptores y a la vez analizaremos los resultados obtenidos al aplicar esta técnica.\n",
        "\n",
        "### Procesos para la obtención de descriptores\n",
        "\n",
        "1. Estructura del Dataset\n",
        "\n",
        "El dataset que trabajaremos se a organizado en función de las categorías seleccionadas:\n",
        "+ Turtle\n",
        "+ Rat\n",
        "+ Guitar\n",
        "+ Glas\n",
        "+ Fork\n",
        "\n",
        "Cada una de estas categorías a sido separadas tanto en el conjunto de entrenamiento como de test. Para este caso trabajamos con un 70% de imágenes para entrenamiento y el 30% para test.\n",
        "\n",
        "2. Extracción del Descriptor Shape Signature en Imágenes\n",
        "\n",
        "Para obtener el descriptor Shape Signature, se llevaron a cabo los siguientes pasos.\n",
        "\n",
        "**Lectura y Procesamiento de Imágenes**\n",
        "\n",
        "+ Como primer paso, se realiza una conversión de la imagen original a escala de grises. Este proceso se aplica a todas las imágenes del dataset. Además, se lleva a cabo la ecualización del histograma para mejorar el contraste de la imagen.\n",
        "\n",
        "+ Como siguiente paso, se realizó la binarización mediante el método de Otsu. Esta técnica consiste en la conversión de una imagen en escala de grises a una imagen binaria. El método de Otsu trabaja calculando el histograma de la imagen en escala de grises y luego prueba diferentes valores de un umbral definido como T. Los píxeles se dividen en dos grupos: uno para el fondo y otro para el objeto a clasificar. Finalmente, la binarización se realiza convirtiendo a negro los píxeles menores que T, mientras que los píxeles mayores o iguales se convierten en blanco. Se decidió usar este método porque automatiza la selección del umbral y es ideal para imágenes en las que existe una clara separación entre el objeto y el fondo.\n",
        "\n",
        "![Lectura y Procesamiento](https://drive.google.com/uc?id=1c0EEpT8U3H2LrOkT4cW6-u2-qIhr9EYt)\n",
        "\n",
        "\n",
        "**Detección de Contornos en Imágenes**\n",
        "\n",
        "+ Se buscan los contornos de la imagen binaria obtenida anteriormente. Únicamente se extraen los contornos externos y se reducen los puntos redundantes en el contorno de la imagen, principalmente para ahorrar memoria. De este paso obtenemos una lista de los contornos detectados, donde cada contorno estará representado por un arreglo de coordenadas (x, y).\n",
        "\n",
        "+ De la lista de contornos obtenida, se selecciona el contorno con el área mayor, lo que nos garantiza que el objeto a clasificar es el más grande de la imagen.\n",
        "\n",
        "![Contornos](https://drive.google.com/uc?id=1dyTskpXEtV_FZbEpvS4U0OaXYvgAmr5n)\n",
        "\n",
        "\n",
        "**Cálculo del Shape Signature**\n",
        "\n",
        "+ Ahora, se calculan los momentos de la imagen, lo que nos proporciona la información geométrica del contorno. Con esos datos, se obtiene el centroide.\n",
        "\n",
        "+ Ahora, con el centroide, se debe obtener la firma de forma o Shape Signature, la cual será una firma de distancias de cada punto del contorno al centroide. Esto nos dará un vector de características que proporcionará una descripción de la forma del objeto.\n",
        "\n",
        "![Shape Signature](https://drive.google.com/uc?id=1tvzsdRUENCmsJLaTMCbLVIPGzqeR6R7-)\n",
        "\n",
        "\n",
        "3. Guardar los Descriptores de Forma\n",
        "\n",
        "+ Los descriptores obtenidos inicialmente son un arreglo de NumPy. Para poder guardarlos en formato JSON, se convierten a una lista de Python. Cabe mencionar que los descriptores serán guardados tanto para el conjunto de entrenamiento como para el conjunto de prueba.\n",
        "\n",
        "![Guardar los Descriptores](https://drive.google.com/uc?id=1dxFSwuc0UIJh0vIWZmb2x5Y4pI7MB5c3)\n",
        "\n",
        "\n",
        "4. Interpolación del Descriptor\n",
        "\n",
        "+ Dado que existe una variación en el tamaño de los descriptores, se vio necesario implementar la interpolación para normalizarlos a una longitud fija. Se utiliza interpolación porque ajusta la longitud de una firma de forma para que tenga un número fijo de puntos, lo que nos garantiza que, a pesar del ajuste, se mantenga la información importante del objeto a clasificar. En resumen, gracias a esto, será posible la comparabilidad entre descriptores.\n",
        "\n",
        "![Interpolación del Descriptor](https://drive.google.com/uc?id=1q9_Z4HC6BXzRVRLxuCvv5S_4SQuSTeqK)\n",
        "\n",
        "\n",
        "5. Clasificación y Similitud\n",
        "\n",
        "+ Ahora se implementa un método para la clasificación de las imágenes. Este método consiste, primero, en la redimensión de la firma de forma de la imagen de prueba y las firmas de entrenamiento. Luego, se comparan las firmas de forma de la imagen de prueba con todas las firmas de las imágenes de entrenamiento utilizando la distancia euclidiana. Para la asignación de una categoría o clasificación, lo que se hace es que la firma más cercana será predicha como la categoría de la imagen de prueba.\n",
        "\n",
        "![Clasificación y Similitud](https://drive.google.com/uc?id=1_hOzrp9mIa7c9IdXzM2DVBCXp5K01rpi)\n",
        "\n",
        "\n",
        "6. Evaluación del modelo\n",
        "\n",
        "+ Para evaluar el modelo, se implementaron dos funcionalidades: una que mide la exactitud del modelo de clasificación y otra que se encarga de generar la matriz de confusión de las categorías utilizadas para la clasificación.\n",
        "\n",
        "### Nivel de precisión del sistema planteado\n",
        "\n",
        "El sistema planteado para las categorías Turtle, Rat, Guitar, Glass y Fork ha obtenido una precisión del 80%. Esto se debe a que, de las 15 imágenes del conjunto de prueba, 12 fueron clasificadas correctamente y 3 fueron clasificadas incorrectamente. Para entender en qué clases hubo problemas en la clasificación, la matriz de confusión nos permitirá interpretarlo.\n",
        "\n",
        "![Clasificación y Similitud](https://drive.google.com/uc?id=1baAYPiHZGWo7Td4rEGGoH07H7Fab2eu1)\n",
        "\n",
        "\n",
        "### Matriz de confusión de las categorías seleccionadas.\n",
        "\n",
        "![Matriz Confusión](https://drive.google.com/uc?id=1UX_HZMaqTJCBB0h6FjCyCKKjPXN_4Y85)\n",
        "\n",
        "Como vimos, el modelo alcanzó una precisión global del 80%. Si analizamos el porqué, obtenemos los siguientes resultados:\n",
        "  + Para la categoría Rat, tenemos una clasificación perfecta. En este caso, las tres imágenes de Rat fueron clasificadas correctamente en la categoría esperada.\n",
        "  + De igual manera, en la categoría Guitar, de las tres imágenes de guitarras del conjunto de prueba, las tres fueron clasificadas correctamente.\n",
        "  + Sigue la misma tendencia la categoría Glass, donde las tres imágenes de prueba son clasificadas correctamente en la categoría esperada.\n",
        "  + Para la categoría Turtle, tenemos el primer error en la clasificación, ya que únicamente se clasifican correctamente dos imágenes, y una de ellas es clasificada como guitarra. Desde mi punto de vista, el error puede deberse a una similitud en la figura; en este caso, podría ser la forma del caparazón de la tortuga, que es similar a la del cuerpo de la guitarra.\n",
        "  +  Finalmente, tenemos la clase Fork, que es la que presenta más problemas en la clasificación, ya que únicamente una figura es clasificada correctamente, mientras que las dos restantes son clasificadas como Glass. De igual manera, desde mi punto de vista, el error puede deberse a una similitud en la forma de la figura, específicamente en la punta de los tenedores y la forma de la copa.\n",
        "\n",
        "Para comprender más a fondo lo que se detalló, el siguiente apartado mostrará las formas que generan confusión.\n",
        "\n",
        "### Ejemplos gráficos de formas que confunde\n",
        "\n",
        "**Clase Fork**\n",
        "\n",
        "![Clase Fork](https://drive.google.com/uc?id=17Uv8ktus_dBjBffG6c7OM4px-Jj9Q1eT)\n",
        "\n",
        "+ Como hemos revisado antes, la clase que más se vio afectada en la clasificación fue la correspondiente a tenedores (Fork). El problema está en que se predice como Glas. Como mencionamos, el error puede deberse a la similitud de forma, en este caso, a la semejanza entre la copa de vidrio y la punta de los tenedores.\n",
        "\n",
        "**Clase Turtle**\n",
        "\n",
        "![Clase Fork](https://drive.google.com/uc?id=1hg5sr25UqTmXGCJ_Dj8IO9QOfv7Z0oDP)\n",
        "\n",
        "+ Tenemos el mismo problema en la clase Turtle o tortuga. En este caso, se comete un error de clasificación al identificarla como una guitarra (Guitar). De igual manera, se considera que el error se debe a una similitud en la forma, específicamente entre el caparazón de la tortuga y el cuerpo de la guitarra.\n",
        "\n",
        "\n",
        "### Conclusión\n",
        "\n",
        "Al aplicar la técnica de Shape Signature, hemos llegado a las siguientes conclusiones. En primer lugar, este enfoque es muy bueno para capturar la forma de los objetos en imágenes simples. Además, es una técnica con un bajo costo computacional, lo que resulta útil en casos donde los recursos pueden ser una limitación.\n",
        "\n",
        "Sin embargo, se experimentaron problemas como la mala clasificación de objetos, ya que puede haber confusiones debido a la similitud de formas. Además, al no considerar características como textura y color, la técnica tiende a ser débil en ese aspecto.\n",
        "\n",
        "En conclusión, la técnica de Shape Signature ha demostrado ser una herramienta muy eficaz para la clasificación basada en la forma de los objetos.\n",
        "\n",
        "\n",
        "### Enlace al repositorio\n",
        "\n"
      ],
      "metadata": {
        "id": "LhBROsfF9yhQ"
      }
    }
  ]
}